---
title: 'Evaluating Spatially-Enabled Machine Learning Approaches to Depth to Bedrock Mapping, Alberta, Canada'
author: 'Pawley, S.M., Atkinson L., Utting, D.J., Hartman, G.M.D., Atkinson, N.'
format:
  html:
    fig-dpi: 600
date: '2023-11-23'
bibliography: zotero.bib
csl: plos-one.csl
link-citations: true
editor_options: 
  chunk_output_type: console
execute: 
  echo: false
  message: false
  warning: false
self-contained: true
editor: 
  markdown: 
    wrap: 72
---

```{r libraries}
library(here)
library(glue)
library(tidyverse)
library(patchwork)
library(ggside)
library(ggrepel)
library(colorspace)
library(RColorBrewer)
library(cptcity)
library(sf)
library(terra)
library(tidyterra)
library(ggnewscale)
library(sfdep)
library(RColorBrewer)
library(gt)
library(ggnewscale)
library(tidymodels)
library(tidyposterior)
library(pins)
library(httr2)
source(here("R/plots.R"))
source(here("R/dtb.R"))

n_cores <- parallel::detectCores()

theme_set(theme_bw())
```

# Abstract

Maps showing the thickness of sediments above the bedrock (depth to
bedrock, or DTB) are important for many geoscience studies and are
necessary for many hydrogeological, engineering, mining, and forestry
applications. However, it can be difficult to accurately estimate DTB in
areas with varied topography, like lowland and mountainous terrain,
because traditional methods of predicting bedrock elevation often
underestimate or overestimate the elevation in rugged or incised
terrain.

Here, we describe a machine learning spatial prediction approach that
uses information from traditional digital elevation model derived
estimates of terrain morphometry and satellite imagery, augmented with
spatial feature engineering techniques to predict DTB across Alberta,
Canada. First, compiled measurements of DTB from borehole lithologs were
used to train a natural language model to predict bedrock depth across
all available lithologs, significantly increasing the dataset size. The
combined data were then used for DTB modelling employing several
algorithms (XGBoost, Random forests, and Cubist) and spatial feature
engineering techniques, using a combination of geographic coordinates,
proximity measures, neighbouring points, and spatially lagged DTB
estimates. Finally, the results were contrasted with DTB predictions
based on modelled relationships with the auxiliary variables, as well as
conventional spatial interpolations using inverse-distance weighting and
ordinary kriging methods.

The results show that the use of spatially lagged variables to
incorporate information from the spatial structure of the training data
significantly improves predictive performance compared to using
auxiliary predictors and/or geographic coordinates alone. Furthermore,
unlike some of the other tested methods such as using neighbouring point
locations directly as features, spatially lagged variables did not
generate spurious spatial artifacts in the predicted raster maps. The
proposed method is demonstrated to produce reliable Manuscript Click
here to access/download;Manuscript;Manuscript.docx results in several
distinct physiographic sub-regions with contrasting terrain types, as
well as at the provincial scale, indicating its broad suitability for
DTB mapping in general

# Introduction

The thickness of surficial materials covering the bedrock surface (depth
to bedrock, or DTB) represents an important consideration in earth and
environmental sciences. In geology, the bedrock surface represents a
regional unconformity whose surface expression varies from outcropping,
to being buried by a variable thickness of geologically younger
sediments that can range from a few centimetres up to several kilometres
in depth. Owing to the often-significant differences in physical
characteristics between bedrock and overlying unlithified deposits, DTB
represents a key consideration of many geological, environmental, and
geotechnical applications that are impacted by variations in near-
surface sediment and rock properties. For example, thick and
unconsolidated sediments host components of water-bearing, permeable
strata that represent sources of potable groundwater, making information
on DTB an important requirement for hydrogeological assessments at a
regional or global scale [@graaf2015]. Mapping spatial variations in DTB
is valuable for the identification of sand and gravel deposits with
aggregate potential, or for determining areas of thin sediment cover
that represent suitable targets for mineral deposit exploration and
development [@andrewsThicknessNeogeneQuaternary2011]. Regions with
deeply buried bedrock can be subject to increased risks from geohazards
particularly due to slope failures occurring in geotechnically soft/weak
sediments, or from amplified ground shaking in earthquake- prone
regions, making DTB a major factor within geotechnical and seismic
hazard assessments [@anbazhaganInfluenceRockDepth2013]. Finally,
information on DTB is a prerequisite to describe landscape-scale
variations in numerous other surface properties such as run-off and
sub-surface flow [@mirus2013; @FreerBedrockTopographySubsurfaceFlow],
soil organic carbon stocks [@HenglSoilCarbonAB], and
erosion/sedimentation [@gmd-10-4577-2017].

The most common method for mapping spatial variations in DTB involves
using geological picks from boreholes and spatial interpolation
techniques to create an elevation surface of the bedrock. The total
thickness of sediment is calculated by subtracting the interpolated
bedrock surface from the ground elevation
[@mayerDepthBedrockCoventry2008; @maccormackUsingMultipleVariogram2018;
@andrewsThicknessNeogeneQuaternary2011; @andriashek2007buried;
@andriashek2003quaternary]. However, in areas without agricultural,
urban, or industrial development, borehole data needed to support
traditional spatial interpolations may be scarce. This can be especially
challenging in regions with complex and/or rugged bedrock topography
because interpolations based on sparse point data tend to produce overly
smooth predictions that underestimate the bedrock elevation in areas
with rapid terrain changes, leading to significant errors when
calculating DTB [@siska2005; @chungEstimatingPositionVariability2012].
An alternative approach is to interpolate DTB directly based on the
assumption that the bedrock surface closely follows the land surface
[@chungEstimatingPositionVariability2012; @gaoBedrockTopography2007;
@sollerMapBedrockTopography2018]. However, this assumption does not hold
true in intermontane valleys [@meyEstimatingFillThickness2015] and can
result in unrealistic predictions in lowland areas
[@chungEstimatingPositionVariability2012]. Geophysical surveys using
techniques such as high-resolution airborne resistivity have also
provided detailed, continuous information about bedrock depth and
near-surface stratigraphy
[@christensenCombiningAirborneElectromagnetic2015;
@dawsonCostEffectiveApproach2018; @oldenborgerBedrockMappingBuried2016].
However, these methods can be expensive to use over large areas and
still require adequate borehole data for calibration.

Recently, information from digital elevation models (DEMs) and other
remote sensing datasets has been used with statistical and machine
learning models to understand spatial variations in the thickness and
composition of surficial materials based on terrain and environmental
characteristics. Studies using single-layer neural networks and ensemble
tree methods have been used to predict DTB at regional
[@meyEstimatingFillThickness2015; @wilfordRegolithDepthMap2016;
@yan2020; @furzeHighResolutionRandomForest2021] and global scales
[@shangguanMappingGlobalDepth2017]. However, most of these studies have
achieved only moderate predictive accuracy (around 0.4-0.7 r^2^) or have
been applied in regions with relatively shallow DTB, where the
correlation to land surface topography is expected to be high. A
potential limiting factor on predictive performance is that terrain and
environmental variables may not be sufficient to explain spatial
variations in DTB, and the concept of spatial autocorrelation, which is
essential to many spatial interpolation methods, has not been
incorporated into the machine learning process. Recent developments in
machine learning approaches for spatial interpolation include using
various spatial feature engineering approaches to potentially allow
algorithms to develop rules that consider spatial location
[@behrens2018; @hengl2018; @kiely2020; @sekulic2020]. Because the
prediction of deeply buried geological surfaces is likely to depend on
the spatial location of the training points in addition to landscape
relationships, incorporating geographic features into the modeling
process may improve the predictive power of machine learning DTB models.

In this study, we explore the use of machine learning approaches for
mapping DTB in the Province of Alberta, Canada (@fig-study-region) using
a large dataset of subsurface data and terrain predictors. We first
developed a method to supplement existing bedrock topography picks using
a natural language model to increase the spatial coverage of the
training data. We then used several machine learning algorithms and
different feature engineering strategies to model these training data,
allowing the models to incorporate information about spatial
autocorrelation and spatial structure of the training data. Finally, we
evaluated the performance of these models in terms of their predictive
accuracy and the geological plausibility of the predicted maps and
derived bedrock topography surfaces.

```{r figure-study-region}
#| fig-height: 7
#| fig-width: 6
#| layout-nrow: 2
#| label: fig-study-region
#| fig-cap: |
#|   Topography of Alberta displayed in metres above sea level (masl). 
#|   Rectangular bounding boxes show the locations of the
#|   sub-regions that are used in the modelling experiments. Dashed lines show
#|   the thalwegs of major buried bedrock palaeochannels. The inset map shows
#|   the three physiographic regions of Canada that Alberta occupies
#|   [@bostockPhysiographicRegionsCanada2014].
epsg <- 3978

bnd <- request("https://geospatial.alberta.ca/titan/rest/services") |> 
  req_url_path_append("boundary/goa_administrative_area/MapServer/0/query") |> 
  req_url_query(f = "geojson", where = "1=1", outFields = "*", returnGeometry = "true") |> 
  pluck("url") |> 
  st_read(quiet = TRUE) |> 
  st_transform(3402)

dem <- rast(here("data/processed/predictors.tif"))$dem

dem <- dem |> 
  crop(bnd) |> 
  mask(bnd)

board_ags <- board_url(c(
  thalwegs = "https://static.ags.aer.ca/files/document/DIG/DIG_2018_0001.zip"
))

board_ags |> 
  pin_download("thalwegs") |> 
  unzip(exdir = tempdir())

thalwegs <- 
  st_read(file.path(tempdir(), "thalweg_ln_ll.shp"), quiet = TRUE) |> 
  st_transform(3402)

thalweg_filter <- c(
  "Exposed",
  "Reoccupied",
  "Partly exposed-valley fill",
  "Palimpsest-reoccupied"
)

thalwegs <- thalwegs |>
  drop_na(EXPOSURE) |>
  filter(!EXPOSURE %in% thalweg_filter)

physio <-
  st_read(here("projdata/physio-pettapiece.gpkg"), quiet = TRUE) |>
  filter(
    str_detect(DISTRICT, "Front Ranges") |
      str_detect(DISTRICT, "Clear Hills") |
      str_detect(DISTRICT, "Swan Hills") |
      str_detect(DISTRICT, "Russell Lake Upland") |
      str_detect(DISTRICT, "Cameron Hills") |
      str_detect(DISTRICT, "Birch Mountains") |
      str_detect(DISTRICT, "Cypress Hills") |
      str_detect(DISTRICT, "Caribou Mountains") |
      str_detect(DISTRICT, "Tazin")
  ) |>
  mutate(label = DISTRICT) |>
  mutate(label = str_split(label, " ", n = 2, simplify = TRUE)[, 2]) |>
  mutate(
    label = if_else(label == "Front Ranges", "Rocky Mountains", label),
    label = if_else(
      label == "Cypress Hills Plateau", "Cypress \n Hills", label
    ),
    label = if_else(
      label == "Russell Lake Upland", "Buffalo Head \n Hills", label
    ),
    label = if_else(
      label == "Tazin River Upland", "Canadian \n Shield", label
    ),
  )


canada_physio <- request("https://maps-cartes.services.geo.ca/server_serveur/rest/services") |> 
  req_url_path_append("NRCan/phys_reg_en/MapServer/1/query") |> 
  req_url_query(f = "geojson", where = "1=1", outFields = "*", returnGeometry = "true") |> 
  pluck("url") |> 
  st_read(quiet = TRUE) |> 
  st_transform(3402)

canada_physio <- canada_physio |> 
  select(SubRegionE) |>
  group_by(SubRegionE) |>
  summarize(SubRegionE = first(SubRegionE)) |>
  mutate(SubRegionE = str_to_title(SubRegionE)) |>
  st_cast() |>
  st_transform(epsg) |>
  drop_na(SubRegionE) |>
  st_as_sf() |>
  filter(SubRegionE %in% c("Interior Plains", "Rocky Mountain Area", "Kazan Region")) |> 
  mutate(
    SubRegionE = case_match(
      SubRegionE,
      "Rocky Mountain Area" ~ "Cordillera",
      "Kazan Region" ~ "Kazan",
      "Interior Plains" ~ "Interior Plains"
    )
  )

ab_bnd <- bnd |>
  mutate(label = "Alberta") |>
  st_transform(epsg)

inset <- ggplot() +
  geom_sf(data = canada_physio, aes(fill = SubRegionE), show.legend = FALSE) +
  geom_sf(data = ab_bnd |> st_transform(epsg), alpha = 0.5) +
  geom_label_repel(
    data = canada_physio,
    aes(label = SubRegionE, geometry = geometry),
    stat = "sf_coordinates",
    label.size = 0,
    size = 2
  ) +
  scale_fill_brewer() +
  theme(
    axis.title = element_blank(),
    axis.text = element_blank(),
    plot.background = element_rect(fill = "transparent", colour = NA),
    axis.ticks = element_blank()
  ) +
  guides(fill = guide_legend(ncol = 3))

locations <- tribble(
  ~location, ~lon, ~lat,
  "Edmonton", -113.468710, 53.550140,
  "Calgary", -114.09, 51.05,
  "Fort McMurray", -111.3790, 56.7267
) |>
  st_as_sf(coords = c("lon", "lat"), crs = 4326) |>
  st_transform(3402)

bnds <- list(
  nwt = st_bbox(c(xmin = 220554, xmax = 478118, ymin = 6427403, ymax = 6656935), crs = 3402),
  mnts = st_bbox(c(xmin = 459473, xmax = 530280, ymin = 5621257, ymax = 5688716), crs = 3402),
  saos = st_bbox(c(xmin = 633875, xmax = 821422, ymin = 6109081, ymax = 6295954), crs = 3402),
  wcab = st_bbox(c(xmin = 265324, xmax = 463220, ymin = 5923836, ymax = 6093134), crs = 3402)
)

bnds_vect <- c(
  st_as_sfc(bnds$nwt),
  st_as_sfc(bnds$saos),
  st_as_sfc(bnds$mnts),
  st_as_sfc(bnds$wcab)
)
bnds_vect <- st_sf(name = c("NWAB", "SAOS", "MNTS", "WCAB"), geometry = bnds_vect)

main <- ggplot() +
  geom_spatraster(data = dem) +
  geom_sf(data = thalwegs, linetype = 6) +
  geom_sf(data = bnds_vect, fill = "white", linewidth = 0.5, alpha = 0.3) +
  geom_sf(data = physio, fill = "transparent") +
  geom_label_repel(
    data = physio,
    aes(label = label, geometry = geom),
    size = 2.5,
    stat = "sf_coordinates",
    label.size = 0
  ) +
  geom_label_repel(
    data = bnds_vect,
    aes(label = name, geometry = geometry),
    size = 2.5,
    stat = "sf_coordinates"
  ) +
  scale_fill_hypso_c() +
  labs(fill = "Elevation [masl]") +
  theme(
    axis.title = element_blank(),
    plot.margin = margin(0, 0, 0, 0),
    plot.title = element_text(size = 10)
  )

main + inset_element(inset, 0, -0.17, 0.4, 0.4)
```

# Regional setting

Alberta occupies \~662,000 km^2^ within the southern Interior Plains of
Western Canada, with small portions occurring within the Canadian Shield
and Western Cordillera (@fig-study-region). Alberta is host to diverse
physiography that descends in elevation and relief from the Rocky
Mountains and Foothills (3600 - 1000 m above sea level, masl)
northeastward into the Eastern/Western Alberta plains (400 - 1500 masl)
and Northern Alberta lowlands and plains (160 - 500 masl). Isolated
uplands occur across Alberta and rise from 300 - 500 masl at their base
to summits that range from 750 - 1400 masl. These include the Cypress
Hills and Swan Hills in the southern and central regions of the
province; the Clear Hills, Buffalo Head Hills, and the Cameron Hills in
the northwest; the Caribou Mountains in the north; and the Birch
Mountains in the northeast.

The thickness of sediments above bedrock varies substantially across
Alberta, ranging from zero thickness (bedrock outcrops) to 400 m in
depth within the eastern and northern parts of the province where a
series of palaeochannel systems are filled with stratified and
non-stratified sediments. Areas of thin sediment cover generally occur
in the west, particularly in the Rocky Mountains and Foothills regions,
although thin sediments also occur in two low-relief corridors through
southern Alberta where Quaternary ice streams removed most pre-existing
sediment.

# Materials and methods

## Data and preprocessing steps

### Borehole and outcrop data

```{r prepare-pick-sources}
picks <- readRDS(here("projdata/picks.rds")) |> 
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326)

cnts <- summarize_data_type(picks)
n_boreholes <- filter(cnts, data_type == "Borehole") |> pull(n)
n_outcrops <- filter(cnts, data_type == "Outcrop") |> pull(n)
n_pseudo <- filter(cnts, data_type == "Pseudo-observation") |> pull(n)

source_perc <- summarize_borehole_sources(picks)

pc_ww <- source_perc |> 
  filter(source_type == "Water well") |> 
  pull(pct)

pc_og <- source_perc |> 
  filter(source_type == "Oil and gas") |> 
  pull(pct)
```

The data used for mapping DTB was compiled from three sources
(@fig-pick-data) including:

1.  Bedrock top picks made from geological boreholes (n =
    `r n_boreholes`) with `r pc_ww`% being derived from water wells,
    `r pc_og`% from oil and gas wells, and the remaining being derived
    from other sources such as geotechnical investigations, and mineral
    exploration boreholes.

2.  Bedrock outcrop locations (n = `r n_outcrops`) consisting of field
    observations, outcrops digitized from previously published
    geological maps and reports, and remotely interpreted observations
    using high-resolution satellite imagery.

3.  Pseudo-observations (n = `r n_pseudo`) of DTB derived from digitized
    contour maps of bedrock surface elevation but where the original
    data sources for the contour interpretations have not been
    explicitly captured. These included a small number (n = 346) of
    synthetically generated observations on steep-mountainous slopes
    (DTB = 0) and points (n = 200) generated from the elevation of other
    subsurface units that are known to represent the uppermost bedrock
    unit.

```{r figure-pick-data}
#| fig-height: 5
#| fig-width: 5
#| label: fig-pick-data
#| fig-cap: |
#|   Distribution of the training data categorized by data source (borehole, outcrop, pseudo-observation).
theme_set(theme_bw())

picks_vct <- picks |>
  mutate(
    data_type = as.factor(data_type),
    data_type = forcats::fct_recode(
      data_type,
      "Pseudo-observation" = "Contour",
      "Borehole" = "Shotholes",
    )
  ) |>
  vect() |> 
  project("EPSG:3402")

ab_bnd_vct <- ab_bnd |>
  vect() |>
  project("EPSG:3402")

picks_vct <- mask(picks_vct, ab_bnd_vct)

ggplot() +
  geom_spatvector(
    data = picks_vct, aes(color = data_type), shape = 16,
    size = 0.1
  ) +
  geom_spatvector(data = ab_bnd_vct, fill = "transparent") +
  labs(color = NULL) +
  scale_color_discrete_qualitative(palette = "Dynamic") +
  guides(color = guide_legend(override.aes = list(size = 3))) +
  theme(legend.position = "top")
```

### Terrain and remote sensing datasets

A resampled version of the openly available ALOS DEM [@tadono2014] at
500 m resolution was used as the primary source of topographic
information for the study. This DEM was used to generate a suite of
morphometric derivatives using the 'Rsagacmd' package [@Rsagacmd] in the
R statistical programming language in conjunction with the open-source
SAGA-GIS software [@conradSystemAutomatedGeoscientific2015]. The
morphometric parameters (@fig-predictors) broadly describe three types
of relief, comprising:

1.  Local morphology, based on standard terrain measures such as slope
    angle, curvature, and topographic roughness, which are calculated
    using relationships between pixels in locally moving windows across
    the DEM.

2.  Regional morphology, based on calculations that model relationships
    between physiographic elements of the landscape using the DEM in its
    entirety, such as relative elevation differences to valleys and
    ridges, topographic openness, or the flatness of valley bottom
    areas.

3.  Topographic wetness, based on relationships between slope angle and
    flow accumulation.

```{r figure-terrain-features}
#| fig-height: 8
#| fig-width: 10
#| label: fig-predictors
#| fig-cap: |
#|   Examples of the topographic features for a region of NE Alberta. The
#|   displayed terrain ruggedness index and vector ruggedness measure were
#|   calculated using a 1-cell radius window.

theme_set(theme_bw())

predictors <- rast(here("data/processed/predictors.tif"))

example_ext <- ext(c(
  xmin = 631215.9,
  xmax = 811080.9,
  ymin = 6255494.2,
  ymax = 6442889.2
))

predictors_roi <- crop(predictors, example_ext)
plot_terrain_predictors(predictors_roi)
```

The derived terrain features were augmented with spectral data from a
MODIS9A best pixel mosaic, created from early to late summer scenes
during 2020. A summary of the features is provided in @tbl-features.

```{r table-features}
#| label: tbl-features
#| tbl-cap: |
#|   Terrain, geographic and spatial lag features used in the modelling process.
#|   The abbreviated feature names refer to the labels used in the figure. Some
#|    features occur in conjunction with integer suffixes such as ‘vdchn’ and 
#|    ‘strahler’ which refer to the stream order used to calculate vertical or 
#|    horizontal distances respectively.

predictors_tbl <- tribble(
  ~Feature, ~Description,
  "Channel base elevation (baselevel)",
  "Topographic surface interpolated from river channel height",
  "Digital Elevation Model (dem)", "dem",
  "Slope", "Slope angle (radians)",
  "Curvature (longc, crosc)",
  "Horizontal/vertical components of slope curvature",
  "Terrain ruggedness index (tri)",
  "Absolute difference between pixel centre and neighbours",
  "Vector ruggedness measure (vrm)",
  "Variation in slope and aspect",
  "Texture (texture)",
  "Spatial density of pits and peaks in the DEM",
  "Height under/over drainage/summits (ho, hu)",
  "Height over drainage / under summits",
  "Normalized height (nh)",
  "Relative position between drainage and summits",
  "Standardized height (sh)",
  "Normalized Height multiplied by the DEM",
  "Topographic openness (pos, neg)",
  "Proportion of visible sky/ground",
  "Multiscale topographic position index (mtpi)",
  "Standardized difference between DEM cell and mean of neighbours",
  "Multiresolution index of valley bottom flatness (mrvbf)",
  "Relative flatness and lowness of valley floor areas",
  "Vertical distance to channels (hacn)",
  "Elevation above channel base",
  "Valley depth (valley_depth)",
  "Elevation below a surface interpolated from ridge lines",
  "Relative slope position (rsp)",
  "Relative height between channel and ridge elevation",
  "SAGA Wetness Index (twi)",
  "Modified topographic wetness index",
  "X,Y coordinates",
  "Grid coordinates"
)

predictors_tbl |>
  gt() |>
  tab_options(
    heading.subtitle.font.size = 12,
    table.font.size = 11
  ) |>
  tab_style(list(cell_text(weight = "bold")), list(cells_column_labels(c("Feature", "Description"))))
```

## Machine learning methods

Machine learning and data analysis were performed in the R statistical
programming environment [@base] using the 'tidymodels' suite of packages
[@tidymodels].

### Natural language model of borehole lithologs

Despite the large data compilation efforts, some areas of the study
region - specifically southeast Alberta and the Rocky Mountains and
Foothills had limited data control (mostly shallow observations from
outcrops, @fig-pick-data). To avoid extrapolating the spatial
predictions across these areas, a statistical natural language
processing (NLP) model was used to automatically label previously
uninterpreted water well lithologs that were abundant in these regions.
NLP techniques are increasingly being used to extract information from
geological text-based datasets, the results of which can then be used
for geological modelling [@padarian2019;
@fuentes3DLithologicalMapping2020].

The NLP model was trained upon the text descriptions of lithologs from
compiled borehole dataset using a binary 'bedrock' or 'surficial'
classification. Text descriptions (material type, description, and
colour) for each logging interval were standardized by removing stop
words and were tokenized using a bag-of-words approach. For lithological
descriptions, only unigrams were retained because the ordering of the
terms in the relatively simple water well descriptions did not convey
much information (e.g., sand and silt, or silt and sand might be used
interchangeably). For colour descriptions, bigram word sequences were
used to retain terms such as 'dark gray' that are commonly used to
describe units such as bedrock shale. Additional features were also
added to the model based on simple text-matching patterns, as well as
features that describe the number of intervals in the log, the maximum
depth of the borehole, and the relative depth and relative thickness of
the intervals.

For the NLP modelling, the XGBoost classifier was used [@xgboost], which
is an ensemble decision tree-based algorithm that uses an additive,
forward stepwise process where additional decision trees are fitted to
correct the predictions from previous trees. XGBoost does this by using
gradient descent to minimize the loss when adding new trees.

The predicted litholog intervals were then used to define the bedrock
top based on the uppermost predicted bedrock interval that occurs
beneath all surficial intervals. This approach, which ignores isolated
intervals that are predicted as bedrock but overlie deeper surficial
units, mitigates the problem that many Quaternary successions contain
glaciotectonically displaced intervals of bedrock. The final predicted
borehole DTB locations were used to augment the compiled
borehole/outcrop dataset in regions where existing point-based estimates
were sparse, only where no other observations were available within a 3
km radius.

### Depth to bedrock spatial prediction

Three machine learning regression algorithms were evaluated: Random
forests, XGBoost, and Cubist regression trees. The emphasis on using
tree-based algorithms is based on their efficiency at scaling to large
datasets and their popularity in previous spatial predictions, which
reflects the theoretical capability of tree-based models to model
spatial variations via recursive partitioning of the feature and
geographic space [@hengl2018].

Random forests (RF) [@breimanRandomForests2001] construct a 'forest' of
uncorrelated decision trees using random subsets of the training data.
This approach aims to reduce the overall variance of the predictions and
mitigates over fitting by averaging predictions from many individual
trees. In this study, we test both the original random forest
implementation where the node splits in each tree utilize the most
discriminative threshold, as well as the 'extra trees' configuration
[@geurts2006], which uses the best threshold from several randomly
generated splits. The latter is computationally more efficient, produces
a smoother regression model, and in some cases can lead to slightly
improved predictive performances based on the increased diversity of the
forest.

For the boosted tree algorithms, the previously described XGBoost model
and a second boosted tree algorithm, Cubist were used in the spatial
predictions [@quinlanLearningContinuousClasses1992; @quinlan1993].
Cubist uses a different boosting approach as compared to XGBoost, where
each tree corrects the predictions from the previous tree by subtracting
the residual from the previous tree from the current tree's prediction,
summarized by:

$y^*_{(m)} = y - (y_{(m-1)} - y)$

where $y^*_{(m)}$ is the modified prediction for the current tree, and
where $(y_{(m-1)} - y)$ is the residual from the previous tree. Cubist
also differs in that it uses linear regression models at the terminal
nodes of the tree, which allow the trees to extrapolate and can prevent
trees from under-predicting the high and low tails of the data. An
additional feature of Cubist is that the predictions can also be
adjusted based on the values of neighbouring points in the feature
space, with the weighting of neighbouring points using inverse distance
weights.

For each model, the most pertinent hyperparameters that typically
influence the fitting behaviour were optimized across a range of values
using a grid search (for Random forests and Cubist) or randomized search
(for XGBoost) approach (@tbl-hyperparameters). For Random forests, these
including the minimum number of observations to occur in a leaf-node
(min_n), the number of predictors that are randomly available at each
node split (mtry), and the criteria used in the decision tree splits
(splitrule). For XGBoost, in addition to mtry, the maximum allowable
depth of each tree (tree_depth) was tuned, along with the learning rate
and the proportion of observations that are randomly sampled for each
tree (subsample). Finally for Cubist, the number of boosting iterations
(committees) and number of neighbours used in the accuracy adjustment
(neighbours) were tuned.

```{r table-hyperparameters}
#| label: tbl-hyperparameters
#| tbl-cap: |
#|   Hyperparameter tuning ranges for the machine learning models. The RF and 
#|   Cubist models were tuned using a grid search with three levels, and the 
#|   XGBoost model was tuned between the parameter range using a randomized
#|   search with 25 iterations.
hyperparameters <- tibble(
  Model = c(
    "RF",
    "XGB",
    "Cubist"
  ),
  Hyperparameters = c(
    "min_n, mtry, splitrule",
    "max_depth, subsample, learn_rate, mtry",
    "neighbors, committees"
  ),
  `Parameter Ranges` = c(
    "[1, 25], [5, 38], [variance, extratrees]",
    "[5, 21], [0.6, 1.0], [0.05, 0.2], [5, 38]",
    "[0, 9], [10, 50]"
  )
)

hyperparameters |>
  gt() |>
  tab_options(
    heading.subtitle.font.size = 12,
    table.font.size = 11
  )
```

### Spatial feature engineering approaches

Recently, there has been increasing interest in applying machine
learning methods to spatial interpolation and a series of methods have
been proposed, based on introducing spatial features into the modelling
process to incorporate information from the spatial structure of the
training data. These spatial features include using: (a) x/y coordinates
as features; (b) proximity measures to reference locations in the
spatial domain, and (c) features derived from surrounding spatially
proximal observations, either as spatial lag variables
[@diEnsemblebasedModelPm22019; @liEstimatingGroundlevelPm2017] or using
the values of neighbouring points directly as in the 'RFSI' approach
[@sekulic2020]. For example, in the 'RFsp' method, Random Forest models
were augmented by proximity measures using Euclidean distances to each
sample point in the training data [@hengl2018]. However, this is only
computationally practical for small datasets, otherwise the number of
generated features becomes extremely large (for our study, would involve
adding \~ 200,000 predictors to the model, one distance measure per
point, and would require \> 450GB of RAM for the training data alone).
In contrast, [@behrens2018] demonstrated comparable results to
regression kriging using only five Euclidean distance measures or
'fields' (EDFs) using arbitrary reference locations. Other studies have
used proximities to geologically based reference locations, such as the
edges of valley walls [@meyEstimatingFillThickness2015] or bedrock
outcrops [@kitterodEstimatingUnconsolidatedSediment2017]. In contrast,
using the values of neighbouring spatial point locations such as in the
'RFSI' approach [@sekulic2020] is conceptually more similar to
traditional spatial interpolation techniques and was shown to outperform
the RFSp approach in some datasets, and is computationally practical for
large datasets.

To find the best spatial feature engineering approach for DTB modelling,
each of the tested machine learning algorithms was trained using five
different sets of features, consisting of:

1.  **feature set T**, containing terrain and MODIS data only without
    any additional features being introduced to specifically account for
    spatial dependence.

2.  **feature set T+CRDS**, where x/y coordinates are added to the first
    feature set.

3.  **feature set T+EDFs**, containing the terrain and MODIS data,
    augmented by the EDFs approach using distances to five reference
    locations (corners and centre of model domain) as per
    [@behrens2018].

4.  **feature set T+NN**, where the target values and distances to
    neighbouring point locations are used directly as additional
    features.

5.  **feature set T+SL**, where spatial lag variables consisting of the
    distance weighted mean of surrounding data points are used as
    additional features.

For the spatial lag variables, the k-nearest neighbouring points to each
training and/or prediction point were queried using the fast kd-tree
search method. Although many new features and summary statistics could
potentially be extracted from both the response and predictor variables,
for parsimony we focused on three features using 5, 10, and 15
neighbouring points. The weighted mean of the response variable y of
these points was then calculated by:

$y_i^* = \frac{\sum_{j=1}^k W_jy_j}{\sum_{j=1}^{k} W_j}$

where $y^*_i$ is the prediction point and $j=1, 2, 3 ... k$ is each
neighbour. The weights of the neighbours were assigned based the
probability density of a Gaussian kernel to provide smooth aggregations
of the surrounding points:

$W(x_i, x_j) = \frac{1}{(\sigma \sqrt{2\pi)}} \exp(-\frac{d(x_i, x_j) P(1 / 2k)^2}{2\sigma^2})$

where Gaussian probability density function has a standard deviation
$\sigma = 1$ and a mean of zero, and where $d(x_i-x_j)$ are the
row-normalized Euclidean distances between points $i$ and $j$, which are
weighted by the quantile of the Gaussian distribution that is equal to
the $1 / 2k$ [@hechenbichler]. This uses the concept that when $k$ is
large, the distances are scaled across a greater width of the Gaussian
distribution, which will make the prediction more sensitive to
neighbours near the prediction point, and when $k$ is small, the
distances are scaled across a narrower width of the distribution,
amounting to a more equal weighting that will smooth and reduce the
variance of the prediction. We note that a wide range of other weight
functions could potentially be used or optimized as a hyperparameter.

Finally, to understand how these augmented spatial features were
influencing the models, feature importance scores were calculated for
each approach using a permutation method based on the ratio in r^2^
scores obtained from predictions using the original model, and
predictions obtained after each variable is permuted. These scores are
presented as relative scores based on dividing each score by the score
of the most important feature for each feature set and model.

### Model validation

10-fold cross-validation was used throughout the modelling process to
provide unbiased estimates of model performance. For the spatial
prediction models, an inner 3-fold cross-validation was also used to
optimize the model's hyperparameters. Model performances were summarized
and compared based on:

-   The RMSE scores on the out-of-fold samples during cross-validation
    to provide a global estimate of model error.
-   For the spatial prediction models, the local Moran's I statistic as
    calculated on the residuals of the out-of-fold samples was used to
    quantify the degree of residual spatial autocorrelation in the
    predictions. Local Moran's I [@Anselin1995LISA] is a local indicator
    of spatial association (LISA) that describes the spatial pattern of
    a feature, in this case, the model's residuals, based on the slope
    of a regression between a feature and its spatially lagged values.
    Rather than displaying the Moran's I directly, point locations that
    have statistically significant I-values ($p \le 0.05$) are
    classified according to the quadrants of the Moran's scatterplot,
    indicating whether each point shows positive or negative spatial
    autocorrelation. Positive spatial autocorrelation in the residuals
    occurs where a point has high residual and is surrounded by
    neighbouring points with high residuals (High-High), or conversely
    where a point has a low residual and is surrounded by neighbouring
    points with low residuals (Low-Low).

The evaluation of the spatial prediction and feature engineering
approaches was performed in four sub-regions of the province
(@fig-study-region), consisting of two lowland sub-regions with thick
deposition sequences (NWAB, SAOS), an upland area containing moderate
variability in DTB (WCAB), and a fourth region with mountainous terrain
(MNTS). The predicted maps from the different combinations of algorithms
and spatial feature engineering techniques were also evaluated
qualitatively in terms of the quality and geological plausibility of the
spatial predictions.

Finally, after the optimal machine learning approach was selected, the
model was retrained on the full dataset to spatially predict DTB across
the province. To place this prediction in context, the results are
compared with DTB maps obtained from the two most popular interpolation
approaches used in DTB / bedrock topography modelling: inverse-distance
weighted (IDW) and ordinary kriging (OK). For the IDW/OK interpolations,
two strategies were used as benchmarks where: (a) DTB is interpolated
directly using ordinary kriging (OK-DTB), and (b) bedrock elevation
surface elevation is interpolated directly using IDW (IDW-BSE). IDW was
used to interpolate bedrock elevation as the response variable because
the data displayed strong spatial non-stationarity and could not be
modelled with a single variogram across such diverse terrain (mountains,
uplands, and plains). IDW interpolation used a weighted average from 16
neighbouring points with a distance-weighting power of 2. The OK
interpolations used variogram models that were fitted using the R
'gstat' package [@gstat] using an exponential model Kriging
interpolation was performed in a local neighbourhood using the closest
16 points.

# Results

## Natural language model classification performance

```{r read-nlp-model}
library(probably)
source(here("R/nlp.R"))

nlp_cv <- readRDS(here("models/resamples-nlp.rds"))

resample_preds <- augment(nlp_cv)

resample_results_dtb <- resample_preds |>
  mutate(.pred_class = make_two_class_pred(
    .pred_Bedrock,
    threshold = 0.5,
    levels = c("Bedrock", "Surficial"),
    buffer = 0.1
  )) |>
  pick_bedrock(option = "last")

picks_waterwells <- picks |> 
  filter(source_type == "Water well") |>
  mutate(id = as.integer(id)) |>
  drop_na(id) |>
  rename(gicwellid = "id")

resample_results_dtb <- inner_join(
  select(picks_waterwells, c(gicwellid, bedrock_dep)),
  resample_results_dtb,
  by = "gicwellid"
)

test_rmse <- rmse(resample_results_dtb, bedrock_dep, .bedrock_dep)
```

Word frequency plots (@fig-wordcloud) show the relative abundances of
geological terms in the cleaned/standardized litholog interval
descriptions that are associated with bedrock and surficial units.
Expected terms such as 'shale' and 'sandstone' characterize bedrock
litholog descriptions, and terms such as 'clay', 'till', 'gravel' and
'rocks' are commonly used in surficial unit descriptions. Other terms
such as 'coal' occur more commonly in bedrock intervals, but also in
surficial intervals (coal is commonly assimilated in glacial deposits).
Colours do not appear to provide such a strong separation between
surficial and bedrock units, except that bedrock intervals are overall
described as 'grey', whereas surficial intervals contain a mixture of
'brown' and 'grey' terms.

```{r fig-wordcloud}
#| label: fig-wordcloud
#| fig-height: 7
#| fig-cap: |
#|   Word frequency plots. Common lithological and colour descriptions
#|   associated with bedrock and surficial litholog descriptions. The width
#|   of the bars displays the proportion of word usage associated with 
#|   surficial and bedrock units. These terms are split into those that relate
#|   to lithology, and those that relate to colour.

```

The predictive performance of the model as evaluated during
cross-validation was high (RMSE = `r round(test_rmse$.estimate, 2)`)
(@fig-nlp-perf). Bedrock top depths from the remaining water wells were
predicted using the trained NLP model and were appended to the compiled
training dataset.

```{r figure-nlp-performance}
#| label: fig-nlp-perf
#| fig-height: 3.5
#| fig-width: 6
#| fig-cap: |
#|   Histogram of the residuals of the NLP model. Shows the differences/residuals (true
#|   bedrock depth - predicted bedrock depth) obtained on the test set.
resample_results_dtb |>
  ggplot(aes(x = bedrock_dep - .bedrock_dep)) +
  geom_histogram(bins = 100) +
  xlab("Difference (m)") +
  ylab("Count") +
  xlim(c(-50, 50)) +
  ggtitle(paste("RMSE:", round(test_rmse$.estimate, 2)))
```

## Depth to bedrock prediction

### Predictive performances

@fig-benchmark shows the RMSE scores resulting from the 10-fold nested
cross-validation. The choice of modelling algorithm does not appear to
significantly affect predictive performance in most of the sub-datasets.
However, the choice of spatial feature engineering approach shows a more
significant effect; models trained using only terrain and MODIS features
(feature set T) are overall ranked last in all sub-datasets, albeit the
differences are small in the two upland and/or mountainous regions. The
inclusion of coordinate or Euclidean distance features into the models
(T+CRDS, T+EDFs) supplies moderate performance benefits. The spatial
neighbours and/or spatial lag methods (T+NN, T+SL) are ranked first,
with the spatial lag approach (feature set T+SL) being ranked first in
three of four sub- datasets (MNTS, SAOS, WCAB), and being equivalent to
the top ranked T+NN method in the NWAB sub-dataset.

```{r figure-scores}
#| fig-height: 5
#| fig-width: 8
#| label: fig-benchmark
#| fig-cap: |
#|   Point range comparisons of RMSE. Mean and standard errors for the tested models
#|   and feature sets for each tested sub-region. The points are ordered on the x-axis based on
#|   the rank of the overall scores for each spatial feature engineering method, per sub-dataset.
theme_set(theme_bw())

# get resample results
cv_res = readRDS(here("models/experiments-cross-validation.rds"))

cv_res_df = cv_res |>
  separate(id, into = c("model", "preproc", "region")) |>
  mutate(
    preproc = case_match(
      preproc,
      "coordinates" ~ "T+CRDS",
      "terrain" ~ "T",
      "neighbors" ~ "T+NN",
      "lags" ~ "T+SL",
      "geodists" ~ "T+EDFs"
    ),
    region = toupper(region)
  ) |>
  unnest(metrics) |> 
  filter(.metric == "rmse") |> 
  select(model, preproc, region, .estimate)

cv_res_agg = cv_res_df |> 
  group_by(region, model, preproc) |> 
  summarize(mean = mean(.estimate), std_err = sd(.estimate) / sqrt(10), 
            .groups = "drop")

cv_res_agg = cv_res_agg |> 
  group_by(region, preproc) |> 
  mutate(sp_score = mean(mean)) |> 
  group_by(region, model) |> 
  arrange(sp_score) |> 
  mutate(rank = row_number()) |> 
  ungroup() |> 
  mutate(
    rank = case_match(
      model,
      "RF" ~ rank - 0.25,
      "Cubist" ~ rank,
      "XGBoost" ~ rank + 0.25
    )
  )

cv_res_agg |> 
  ggplot(aes(rank, mean, colour = model, shape = preproc)) +
  geom_pointrange(aes(ymin = mean - std_err, ymax = mean + std_err)) +
  facet_wrap(vars(region), scales = "free_y") +
  labs(shape = "Spatial method", colour = "Model") +
  xlab("Rank (Spatial method)") +
  ylab("RMSE") +
  scale_colour_brewer(palette = "Dark2") +
  scale_shape_manual(values = c(
    "T" = 16,
    "T+CRDS" = 17,
    "T+EDFs" = 3,
    "T+NN" = 4,
    "T+SL" = 15
  ))
```

To further examine the magnitude of the apparent improvement in
predictive power for the spatial feature engineering approaches, a post
hoc Bayesian ANOVA model was used to estimate the posterior
distributions for the performance metrics. The Bayesian ANOVA model
takes into account that the relatively performance of each method tends
to be similar across each cross-validation resample, i.e., there is a
strong resample-to-resample covariance. This information is lost when
comparing the models based on summarized means/standard errors alone,
which under-powers the ability to detect differences between the
methods. The Bayesian ANOVA approach uses a random effects linear model
to account for the resample-to-resample effects, where a random
intercept term is drawn (with 5000 repeats) from a t-distribution
[@tidyposterior]. From these distributions, the probability that the
overall top-performing spatial feature engineering method (T+SL) is
equivalent to the other methods is assessed.

For brevity, we focus on the RF model because the choice of regression
tree algorithm has relatively little effect in these datasets. From the
posterior distributions of the RMSE scores from the Bayesian linear
model fits (@tbl-bayesian), the best performing feature engineering
method (T+SL) shows a high probability (\gt 0.9) of reducing the RMSE
(compared to a zero reduction) in the NWAB and SAOS sub-datasets when
compared to most of the other spatial feature engineering methods, apart
from the T+NN approach which has similar performance. In contrast, in
the two upland and mountainous sub-datasets, the T+SL method is
essentially equivalent to the other methods.

```{r ropes}
#| label: tbl-bayesian
#| tbl-cap: |
#|   Reductions in RMSE from the posterior estimates of the Bayesian ANOVA model
#|   for pairs of models. Negative values occur when the reference modelling method, Random
#|   forests with the T+SL feature set reduces the RMSE score, and positive values occur where the
#|   RF (T+SL) method increases the RMSE compared to the other model. The probability column
#|   describes the probability that the RMSE scores of the reference method are different compared
#|   to the other model. The bolded text shows the model pairs that have a high probability (> 0.9)
#|   of being different.

perf_data = cv_res_df |> 
  mutate(.estimate = -.estimate) |> 
  filter(model == "RF") |> 
  group_by(model, preproc, region) |> 
  mutate(id = row_number()) |> 
  ungroup() |> 
  pivot_wider(names_from = c(model, preproc, region), values_from = .estimate)

mod = perf_mod(perf_data, seed = 2, iter = 5000, chains = 5, refresh = 0)

mod_summary = tidy(mod) |> 
  summary() |> 
  mutate(across(c(mean, lower, upper), ~ -.x))

ropes <- mod |> 
  contrast_models(
    list_1 = c(rep("RF_T+SL_NWAB", 4),
               rep("RF_T+SL_SAOS", 4),
               rep("RF_T+SL_WCAB", 4),
               rep("RF_T+SL_MNTS", 4)),
    list_2 = c("RF_T_NWAB", "RF_T+CRDS_NWAB", "RF_T+EDFs_NWAB", "RF_T+NN_NWAB",
               "RF_T_SAOS", "RF_T+CRDS_SAOS", "RF_T+EDFs_SAOS", "RF_T+NN_SAOS",
               "RF_T_WCAB", "RF_T+CRDS_WCAB", "RF_T+EDFs_WCAB", "RF_T+NN_WCAB",
               "RF_T_MNTS", "RF_T+CRDS_MNTS", "RF_T+EDFs_MNTS", "RF_T+NN_MNTS"),
    seed = 4
  )

summary(ropes) |> 
  mutate(
    region = str_extract(contrast, "MNTS|SAOS|WCAB|NWAB"),
    contrast = str_remove_all(contrast, "MNTS|SAOS|WCAB|NWAB"),
    contrast = str_replace_all(contrast, "_", " "),
    contrast = str_squish(contrast)
  ) |> 
  separate(contrast, into = c("model1", "model2"), sep = " vs ") |> 
  select(c(model1, model2, region, mean, probability)) |>
  mutate(
    model1 = str_replace(model1, "T\\+SL", "(T+SL)"),
    model2 = str_replace(model2, "T\\+NN", "(T+NN)"),
    model2 = str_replace(model2, "T\\+CRDS", "(T+CRDS)"),
    model2 = str_replace(model2, "T\\+EDFs", "(T+EDFs)"),
    model2 = str_replace(model2, "T$", "(T)"),
  ) |> 
  mutate(mean = -mean) |> 
  group_by(region) |> 
  gt::gt(rowname_col = "model1") |> 
  gt::fmt_number(columns = c(mean:probability), decimals = 2) |> 
  gt::cols_label(
    model1 = "Reference Method",
    model2 = "Comparison Method",
    mean = "Difference (RMSE)",
    probability = "Probability"
  ) |> 
  gt::tab_stubhead(label = "Reference Method") |> 
  gt::tab_spanner(
    label = "Estimates",
    columns = c("mean", "probability")
  ) |> 
  gt::tab_header(
    title = "RMSE differences from posterior estimates"
  ) |> 
  gt::tab_style_body(
    style = cell_fill(color = "lightblue"),
    columns = "probability",
    fn = function(x) x >= 0.89,
    targets = "row"
  )
```

### Feature importance scores

Heatmaps of the feature importance scores for the overall top 20 most
important features (@fig-fimp) show that the importances are
region-dependent, but within each region, broad similarities in the
rankings occur between the different modelling methods.

```{r fig-importances}
#| fig-height: 9
#| fig-width: 7
#| fig-dpi: 600
#| label: fig-fimp
#| fig-cap: |
#|   Relative feature importance scores. r-squared scores normalized relative to the
#|   top scoring feature. Features with low importance scores (< 1%) are omitted from the plot.
#|   The features spatial1-5 refer to the top spatial variables for each method, such as x, y
#|   coordinates, the five EDF variables, the closest five neighbouring points, or the spatial lag
#|   variables using 5, 10 and 15 neighbours.

fimp_data = readRDS(here("models/experiments-importances.rds")) |> 
  separate(id, into = c("model", "preproc", "region")) |>
  mutate(
    preproc = case_match(
      preproc,
      "coordinates" ~ "T+CRDS",
      "terrain" ~ "T",
      "neighbors" ~ "T+NN",
      "lags" ~ "T+SL",
      "geodists" ~ "T+EDFs"
    ),
    region = toupper(region)
  )

fimp_data_formatted = fimp_data |> 
  recode_variables() |> 
  mutate(
    Variable = str_replace(Variable, "^edf|^nn", "spatial"),
    Variable = str_replace(Variable, "lag5", "spatial1"),
    Variable = str_replace(Variable, "lag10", "spatial2"),
    Variable = str_replace(Variable, "lag15", "spatial3"),
    Variable = str_replace(Variable, "xcoords", "spatial1"),
    Variable = str_replace(Variable, "ycoords", "spatial2")
  )

top_features = fimp_data_formatted |> 
  filter(!str_detect(Variable, "dist")) |> 
  group_by(Variable) |> 
  summarize(Importance = mean(Importance, na.rm = TRUE)) |> 
  arrange(desc(Importance)) |> 
  slice_head(n = 20) |> 
  ungroup() |> 
  distinct(Variable) |> 
  pull(Variable)

fimp_top = fimp_data_formatted |> 
  filter(Variable %in% top_features)

fimp_top |> 
  mutate(Importance = if_else(Importance < 0, 0, Importance)) |> 
  ggplot(aes(model, Variable, fill = Importance)) +
  geom_tile() +
  facet_grid(vars(region), vars(preproc), scales = "free") +
  labs(fill = "Importance") +
  scale_fill_distiller(palette = "Spectral", direction = -1, trans = "sqrt") +
  theme_dark() +
  theme(axis.title = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1))
```

In general, features that describe regional variations in relief and
physiographic setting, such as valley depth, elevation/baselevel and
height relative to drainage and ridge positions, are highly influential
in all the models and sub-regions. The importance of features such as
valley depth and proximity to channels is consistent with the
physiographic setting of Alberta, where many rivers incise into bedrock
and the landscape is fundamentally controlled by fluvial erosion and
deposition \[49\]. However, the mountainous sub-region differs in that
spectral features and local relief (such as tri1) also have high
importances, due to the substantial amounts of exposed rock surfaces and
varied terrain.

When spatial features are included in the models, coordinate features
are important in feature sets T+CRDS and T+EDFs. In contrast, when EDFs
are used, only moderate importances are assigned to them by the
algorithms. In feature sets T+NN and T+SL, spatial features that utilize
information from neighbouring points are ranked as highly important, and
this is also accompanied by a significant reduction in the relative
importance of the terrain/spectral features in the two lowland
sub-datasets (NWAB, SAOS), but less so in the two upland areas.

### Residual spatial autocorrelation

@fig-lisa shows the spatial distribution of local association of the
model's residuals, focusing on the RF model predictions in the SAOS
sub-dataset as an example. The LISA maps show many clusters of positive
spatial autocorrelation when only terrain/spectral features are used in
the modelling (feature set T). The extent of positive spatial
autocorrelation is reduced when the T+NN or T+SL feature engineering
approaches are used, but are only slightly reduced based on feature sets
T+CRDS and T+EDFs.

```{r lisa}
#| label: fig-lisa
#| fig.cap: |
#|  Local indications of spatial association (LISA). Examples of LISA statistics shown
#|  for three feature sets (T, T+EDFs, T+NN, T+SL) within the SAOS sub-dataset using the RF
#|  model. These feature sets show that the spatial lag feature engineering approach reduces
#|  the degree of spatial autocorrelation in the predictions compared to when only
#|  terrain/spectral features are used in the modelling.

lisas <- bind_rows(
  list(
    `RF (T)` = extract_lisa(cv_res |> filter(id == "RF_terrain_saos")),
    `RF (T+CRDS)` = extract_lisa(cv_res |> filter(id == "RF_coordinates_saos")),
    `RF (T+EDFs)` = extract_lisa(cv_res |> filter(id == "RF_geodists_saos")),
    `RF (T+NN)` = extract_lisa(cv_res |> filter(id == "RF_neighbors_saos")),
    `RF (T+SL)` = extract_lisa(cv_res |> filter(id == "RF_lags_saos"))
  ),
  .id = "model"
)

lisas |> 
  group_by(model) |> 
  arrange(mean) |> 
  ggplot() +
  geom_sf(aes(colour = mean), size = 0.5) +
  scale_colour_manual(values = c(
    `Insig` = "gray90",
    `Low-Low` = brewer.pal(4, "RdBu")[4],
    `Low-High` = brewer.pal(4, "RdBu")[3],
    `High-High` = brewer.pal(4, "RdBu")[1],
    `High-Low` = brewer.pal(4, "RdBu")[2]
  ), drop = FALSE) +
  labs(colour = "LISA") +
  guides(colour = guide_legend(override.aes = list(size = 2))) +
  facet_wrap(vars(model)) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1, size = 8),
    axis.text.y = element_text(size = 8)
  )
```

### Comparison of the predicted maps

@fig-dtb-regions provides a comparison of the predicted maps from the
different feature engineering approaches and models using the NWAB
sub-region as an example. Spatial variations in DTB in this area are
driven by the occurrence of thick sediment infills associated with a
buried palaeochannel network (@fig-study-region) and thin sediment
occurring along the steeper flanks of the uplands and the margins of
incised river channels. @fig-btopo-regions also provides examples of
associated bedrock topography surfaces as derived by subtracted the DTB
estimations from the DEM.

Although the predicted maps share broad similarities, maps from the
boosted tree methods are characterized by a high degree of local
variability, which gives the DTB and derived bedrock topography maps an
overly rough/noisy appearance. Furthermore, none of the algorithms
adequately predict the local variations in DTB that are associated with
the buried palaeochannels or incised valleys when using either the
terrain (T) and/or coordinates (T+CRDS) feature sets. The use of
coordinate features alone also leads to a 'box-like' pattern to occur in
some of the predictions caused by decision tree splits in the x, y
coordinates, making this approach potentially unsuitable for spatially
predicting DTB. These maps also display other spurious spatial artifacts
that occurred around incised river valleys, which display an inverted
appearance due to a halo of thicker sediment being predicted along the
channel margins [@fig-btopo-regions].

The delineation of the channels is partially improved when using the
T+EDFs feature set. However, some of these maps contain circular spatial
artifacts caused by an abrupt change in the predictions at specific
distances in the Euclidean distance features. The most detailed and
realistic representation of the palaeochannels occurs in maps based on
methods that use information from neighbouring point locations in the
T+NN and T+SL approaches, and the unrealistic halos around incised
channels are also largely removed. However, when using the neighbouring
points directly as in the T+NN approach, a strong Thiessen polygon- like
structure is present in the predictions. Based on the feature importance
scores, this is likely caused by the dominance of the closest
neighbouring point, which without distance weighting, causes the model
to behave like a 1-nearest neighbour interpolation. Consequently, this
spatial feature engineering approach is not considered appropriate for
predicting DTB. In contrast, the maps predicted using the T+SL feature
set consistently yield the most geologically plausible results because
they are free of rapid, step-like changes and other spurious patterns,
but capture the detail of complex geological features such as the narrow
palaeochannels.

```{r figure-dtb-regions}
#| label: fig-dtb-regions
#| fig-height: 9
#| fig-cap: |
#|   Predicted depth to bedrock (DTB) maps for the random forests and Cubist machine learning models and
#|   feature sets.

# read datasets
predictors <- rast(here("data/processed/predictors.tif"))

dtbs = readRDS(here("models/experiments-dtb.rds"))
dtbs = dtbs[grep("nwab", names(dtbs))]
dtbs = lapply(dtbs, unwrap)
dtb_grids = rast(dtbs)

# visual dtb and btopo rasters
newreg <- ext(c(xmin = 250000, xmax = 460000, ymin = 6427500, ymax = 6650000))
dtb_grids <- crop(dtb_grids, newreg)
dtb_grids[dtb_grids < 0] = 0

# plot dtb maps
dtb_selected = c(
  dtb_grids$RF_terrain_nwab,
  dtb_grids$XGBoost_terrain_nwab,
  dtb_grids$Cubist_terrain_nwab,
  
  dtb_grids$RF_coordinates_nwab,
  dtb_grids$XGBoost_coordinates_nwab,
  dtb_grids$Cubist_coordinates_nwab,
  
  dtb_grids$RF_geodists_nwab,
  dtb_grids$XGBoost_geodists_nwab,
  dtb_grids$Cubist_geodists_nwab,
  
  dtb_grids$RF_neighbors_nwab,
  dtb_grids$XGBoost_neighbors_nwab,
  dtb_grids$Cubist_neighbors_nwab,
  
  dtb_grids$RF_lags_nwab,
  dtb_grids$XGBoost_lags_nwab,
  dtb_grids$Cubist_lags_nwab
)

labels_selected = c(
  "RF (T)",
  "XGBoost (T)",
  "Cubist (T)",
  "RF (T+CRDS)",
  "XGBoost (T+CRDS)",
  "Cubist (T+CRDS)",
  "RF (T+EDFs)",
  "XGBoost (T+EDFs)",
  "Cubist (T+EDFs)",
  "RF (T+NN)",
  "XGBoost (T+NN)",
  "Cubist (T+NN)",
  "RF (T+SL)",
  "XGBoost (T+SL)",
  "Cubist (T+SL)"
)

plot(dtb_selected,
  col = colorRampPalette(rev(RColorBrewer::brewer.pal(9, "Spectral")))(50),
  main = labels_selected,
  range = c(0, 350),
  nc = 3
)
```

```{r figure-btopo-regions}
#| label: fig-btopo-regions
#| fig-height: 5
#| fig-cap: |
#|   Derived bedrock topography maps for the machine learning models, using the
#|   terrain-only (T) and spatial lags (T+SL) feature sets as examples.
btopos <- create_btopos(dtb_grids, predictors$dem)

btopos_selected = c(
  btopos$RF_terrain_nwab,
  btopos$XGBoost_terrain_nwab,
  btopos$Cubist_terrain_nwab,
  btopos$RF_lags_nwab,
  btopos$XGBoost_lags_nwab,
  btopos$Cubist_lags_nwab
)

plot(
  btopos_selected,
  col = colorRampPalette(viridis::turbo(9))(50), nc = 3,
  main = c("RF (T)", "XGB (T)", "Cubist (T)", "RF (T+SL)", "XGB (T+SL)", "Cubist (T+SL)")
)
```

## Application to provincial-scale modelling

```{r read-resamples-province}
resamples_prov_kriging <- readRDS(here("models/cross-validation-kriging-prov.rds"))

resamples_prov_kriging$predictions <- 
  map2(resamples_prov_kriging$splits, 
       resamples_prov_kriging$predictions,
       function(split, preds) {
         test = testing(split) |> 
           select(bedrock_dep)
         pred = preds |> 
           st_drop_geometry() |> 
           rename(.pred = "var1.pred")
         bind_cols(test, pred)
       }
  )

resamples_prov_kriging <- resamples_prov_kriging |> 
  unnest(predictions) |> 
  select(id, bedrock_dep, .pred)
  
resamples_prov_rf <- readRDS(here("models/cross-validation-dtb-prov.rds"))

resamples_prov_rf <- resamples_prov_rf |> 
  unnest(predictions) |> 
  select(id, .pred, bedrock_dep)

resamples_slope_rf <- lm(.pred ~ bedrock_dep, resamples_prov_rf)
resamples_slope_ok <- lm(.pred ~ bedrock_dep, resamples_prov_kriging)

rf_rmse <- resamples_prov_rf |>
  group_by(id) |> 
  rmse(bedrock_dep, .pred) |> 
  summarize(mean = mean(.estimate), std_err = sd(.estimate) / sqrt(10))

kriging_rmse <- resamples_prov_kriging |> 
  group_by(id) |> 
  rmse(bedrock_dep, .pred) |> 
  summarize(mean = mean(.estimate), std_err = sd(.estimate) / sqrt(10))
```

From the first assessment, the spatial lag feature engineering approach
using the RF model was selected for the final DTB prediction at a
provincial scale. The resulting RMSE scores show that the RF model has
similar overall scores compared to ordinary kriging (@tbl-scores). The
intercepts of a linear regression fitted to the observed and predicted
observations (@fig-prov-accuracy) are slightly higher than zero for both
RF and OK-DTB (@tbl-scores), indicating that both approaches have a
slight tendency to underestimate DTB at large values and overestimate
DTB at very shallow values. The difficulty of predicting the tails of a
distribution is well known for RF and results from the random process in
the decision trees causing a small portion of trees in the ensemble to
always produce an erroneously low or high prediction.

```{r figure-provincial-accuracy}
#| label: fig-prov-accuracy
#| fig-cap: |
#|   2D bin plots of observed and predicted observations. Cross-validation results
#|   for the final model predictions for the region of Alberta using the selected RF model and
#|   T+SL feature set, compared to a 1:1 relationship (dotted line). Each rectangle represents a
#|   binning of the observed and predicted values, and the colour fill represents the number of
#|   observations in the bin. The solid line is from a linear model fitted to the observed
#|   vs. predicted values.

plot_truth_predicted(resamples_prov_rf)
```

```{r tbl-final-scores}
#| label: tbl-scores
#| tbl-cap: |
#|   RMSE scores for the final spatially lagged RF approach as applied to the
#|   provincial dataset. For comparison, the RMSE scores obtained from ordinary kriging of
#|   depth to bedrock (OK-DTB) are also shown, along with the intercept and slope of linear
#|   models fitted to the truth vs. predicted cross-validation results.

tibble(
  Model = c("RF", "OK-DTB"),
  RMSE = c(rf_rmse$mean, kriging_rmse$mean),
  Std_Err = c(rf_rmse$std_err, kriging_rmse$std_err),
  Intercept = c(resamples_slope_rf$coefficients[[1]], resamples_slope_ok$coefficients[[1]]),
  Slope = c(resamples_slope_rf$coefficients[[2]], resamples_slope_ok$coefficients[[2]])
) |>
  gt() |>
  fmt_number(columns = c(RMSE, Std_Err, Intercept, Slope))
```

Despite similar performances, comparison of the RF predictions to that
produced by the OK-DTB method shows that the machine learning approach
captures distinct aspects of the data (@fig-dtb-vs-kriging). In
particular, the increase in detail in the machine learning predictions
is evident in areas of incised terrain such as in major river valleys,
where interpolating DTB using the ordinary kriging leads to
near-constant DTB estimates within incised areas, and several major
geomorphic elements of the landscape are completely absent in the
predictions, making them geologically unrealistic. Similarly, comparison
of the uncertainty estimate maps from the two methods also shows that
the RF uncertainty map is more detailed and informative by highlighting
several areas of terrain where there is a large uncertainty in DTB, for
example around the flanks of a local upland.

```{r figure comparison-dtb-ml-vs-kriging}
#| label: fig-dtb-vs-kriging
#| fig-cap: |
#|  Comparison of the predicted DTB and uncertainties. The range of the p90 - p10
#|  prediction interval from the RF model with spatial interpolations of DTB using ordinary
#|  kriging (OK-DTB) in the SAOS region. The increased detail and more realistic prediction of
#|  DTB variations around major physiographic features such as river valleys and local uplands
#|  is evident in the RF results.

dtb_prov <- rast(here("outputs/dtb-rf-prov.tif"))
dtb_prov <- setNames(dtb_prov, "RF")

dtb_err <- rast(here("outputs/dtb-rf-prov-pred-int.tif"))
dtb_err <- dtb_err[[3]]
dtb_err <- setNames(dtb_err, "RF Uncert.")
dtb_err <- resample(dtb_err, dtb_prov)

btopo_prov <- resample(predictors$dem, dtb_prov) - dtb_prov

kriging_prov <- rast(here("outputs/kriging-prov.tif"))
kriging_prov <- setNames(kriging_prov, c("OK-DTB", "OK Uncert."))
kriging_prov <- resample(kriging_prov, dtb_prov)
kriging_prov$`OK Uncert.` <- focal(kriging_prov$`OK Uncert.`, w = 3, fun = "mean")

roi <- c(xmin = 633875, xmax = 821422, ymin = 6109081, ymax = 6295954)
roi <- ext(roi)

prov_grids <- c(kriging_prov, dtb_prov, dtb_err)

ggplot() +
  geom_spatraster(data = crop(prov_grids, roi)) +
  facet_wrap(vars(lyr)) +
  scale_fill_viridis_c(na.value = "transparent", option = "turbo", direction = 1) +
  labs(fill = "DTB [m]") +
  theme_bw() +
  theme(
    axis.text = element_text(size = 7),
    axis.text.x = element_text(angle = 90, hjust = 1)
  )
```

Finally, the geomorphic form of the derived bedrock elevation surface
after subtracting the machine learning predictions from the DEM was
compared to the baseline methods when bedrock topography was
interpolated directly (IDW-BSE) using maps and cross-sectional profiles
through the WCAB and NWAB the sub-regions (@fig-profiles). In the NWAB
sub-region, the form of the derived bedrock surface from the RF model is
similar to that obtained from IDW interpolation, apart from it does not
suffer from the 'bullseye' type artifacts that are visible in the IDW
predictions. However, the overall similarity between the derived bedrock
surface and IDW, even when the bedrock surface is deeply buried and
shows little correlation with the surface topography, strongly supports
that the machine learning approach can be used as a surrogate for
long-established spatial interpolation methods for DTB and bedrock
topography mapping.

In contrast, a comparison of cross-sectional profiles through the upland
WCAB sub-region shows that although the geological setting is
characterized by low DTB, and the bedrock topography mirrors the land
surface, the IDW-BSE with no terrain information smoothly interpolates
across major topographic features where data are sparse. This causes the
interpolated bedrock surface to exceed the land surface elevation, and
more problematically, the bedrock topography smoothly interpolates
through high-amplitude variations in the terrain, generating erroneously
large DTB estimates if the bedrock elevation is subtracted from the DEM.
Predictions from the RF model in contrast closely follow the land
surface topography.

```{r figure-cross-sections}
#| label: fig-profiles
#| fig-cap: |
#|   Comparison of the predicted DTB from the RF model with spatial
#|   interpolations of DTB using inverse-distance weighting interpolation (IDW).
#|   (a) Northern Alberta in lowland to moderate relief upland terrain.
#|   (b) West-central Alberta in upland to mountainous terrain.

bnd <- ext(c(xmin = 220554, xmax = 478118, ymin = 6427403, ymax = 6656935))

profile_l <- st_read(
  here("projdata/cross-section-line-rainbow-lake.geojson"),
  quiet = TRUE
)

profile_u <- st_read(
  here("projdata/cross-section-line-wcab.geojson"),
  quiet = TRUE
)

dem <- setNames(predictors$dem, "Land surface")
idw <- rast(here("outputs/idw-prov.tif"))

dem_500 <- terra::resample(dem, dtb_prov)
crs(dem_500) <- crs(dtb_prov)
btopo_prov <- dem_500 - dtb_prov

training <- readRDS(here("data/processed/training-data.rds"))
training$bedrock_elev <- training$dem - training$bedrock_dep

btopo_area <- crop(btopo_prov, bnd)
idw_nwt <- terra::resample(idw, btopo_area)
picks_grid_nwt <- rasterize(
  vect(training, geom = c("xcoords", "ycoords")),
  btopo_area,
  field = "bedrock_elev"
)

picks_grid_nwt <- setNames(picks_grid_nwt, "picks")

grids_nwt <- c(
  idw_nwt,
  focal(btopo_area, 3, "mean", expand = TRUE),
  picks_grid_nwt
)
grids_nwt <- setNames(grids_nwt, c("IDW", "RF", "picks"))

plot_profiles(
  profile_line = profile_l,
  grids = grids_nwt,
  dem = dem,
  label = "A"
)

bnd <- ext(c(xmin = 265324, xmax = 463220, ymin = 5923836, ymax = 6093134))

btopo_area <- crop(btopo_prov, bnd)
idw_wcab <- terra::resample(idw, btopo_area)
picks_grid_wcab <- rasterize(
  vect(training, geom = c("xcoords", "ycoords")),
  btopo_area,
  field = "bedrock_elev"
)

picks_grid_wcab <- setNames(picks_grid_wcab, "picks")
grids_wcab <- c(
  idw_wcab,
  btopo_area,
  picks_grid_wcab
)
grids_wcab <- setNames(grids_wcab, c("IDW", "RF", "picks"))

plot_profiles(
  profile_line = profile_u,
  grids = grids_wcab,
  dem = dem,
  label = "B"
)
```

# Discussion and Conclusions

The predictive performances of several machine learning approaches for
DTB mapping were systematically examined using topographic and
land-surface spectral data in conjunction with several spatial feature
engineering approaches to account for spatial dependence in the training
data locations. We show that adding spatial lag variables provides clear
benefits in terms of increased predictive performances for DTB mapping,
while yielding maps that are geologically plausible and generally free
of spurious spatial artifacts. This is particularly the case for regions
that host thick sediments above bedrock, such as in the NWAB and SAOS
sub-datasets. In these settings, the correlation between surface
topography and bedrock topography is low, and therefore information from
terrain and/or remote sensing predictors will be less relevant to
predicting the topography of a deeply buried surface. The feature
importance scores demonstrate this, with relatively low importance being
assigned to these predictors, and instead, the models strongly leverage
the spatial lag features. However, in upland and mountainous regions
where moderate to strong correlation between surface and bedrock
topography is expected (and is supported by high feature importances)
the spatial lag feature engineering approach does not impede model
performance, and the RMSE scores were still slightly reduced.
Consequently, the proposed machine learning and spatial feature
engineering approach is expected to be particularly valuable for mapping
DTB across other regions that host thick overlying sediments, while
being robust enough to be applied across any type of terrain.

This study also demonstrated that although some proposed methods of
adding additional spatial variables to machine learning models does
increase predictive performances, such as when using the T+EDF spatial
feature engineering method, or when using neighbouring spatial points
directly as features (T+NN), these methods can result in spatial
artifacts in the predicted maps. For the T+NN approach, this is most
likely caused by the model depending on the single closest neighbouring
point, which is essentially a Thiessen polygon interpolation. The EDFs
approach can also lead to 'step-like' patterns in the predicted maps
because the use of linear distance measures does not guarantee a smooth
prediction surface when using tree-based models. Similar issues have
been noted in other studies when using buffer distances as features
[@talebiTrulySpatialRandom2022]. Furthermore, omitting information from
neighbouring spatial locations also resulted in some spurious patterns,
such as 'inverted' river channels, occurring in the predicted maps.
These patterns were eliminated when spatial variables were included in
the model. We interpret this to reflect the tendency of the machine
learning models to strongly leverage the terrain features to adequately
describe the spatial structure of the training data, even when these
features are not providing useful information in deep sediment areas,
which makes the models overly sensitive to spatial patterns in the
raster grids.

In comparison to other approaches for DTB mapping, traditionally used
spatial interpolation methods such as IDW and ordinary kriging suffer
from the issue of needing to choose between interpolating DTB or bedrock
surface elevation. The former approach is more suitable in mountainous
and upland terrain where bedrock elevation is typically highly
correlated with land surface elevation, while the latter is preferred in
regions where the bedrock topography is uncorrelated from land surface
topography, typical of many lowland regions. This is problematic in
regions of mixed physiography, and most studies tend to either generate
multiple separate models [@chungEstimatingPositionVariability2012;
@gaoBedrockTopography2007; @maccormackUsingMultipleVariogram2018] or
resort to an iterative process where the initial results are repeatedly
re-interpolated with synthetic data that has been generated to resolve
problematic areas [@gaoBedrockTopography2007; @slattery2010]. In either
case, this makes the modelling process cumbersome and impossible to
automate. In contrast, the proposed machine learning approach is fully
automated, requiring no human intervention for model fitting, nor does
it require subjective subdivisions to be made in the spatial data. This
represents a major practical advantage of the proposed machine learning
approach over other methods for large scale mapping because it can use
information from a wide range of auxiliary variables in an automated
manner, while also behaving similarly to other spatial interpolation
methods in the extreme case of where the auxiliary predictors provide
limited information for predicting DTB. Other advantages are the absence
of requirements for spatial stationarity, and that the proposed approach
can handle massive datasets and could be extended to global data through
parallel and distributed computing.

Finally, there are several methodological aspects that may further
improve predictive performances and warrant further studies,
particularly in terms of using differing number of neighbours,
additional combinations of spatial weight functions. Spatial lag
features could also potentially be generated from the predictor
variables rather than just aggregating information from the response
variable (DTB) at surrounding spatial locations. This latter approach
could help the model 'learn' new information from the predictors
themselves, for example, using the variation in surface topography from
neighbouring locations to assist in the prediction. The same approach
has strong potential for any spatial classification models where the
predicted categories exhibit a degree of spatial dependence on the
location of training samples.

Overall, this study adds to growing body of research that the use of
machine learning models with spatial features that account for spatial
structure/autocorrelation provides an alternative and robust approach
for making spatial predictions, and which in some cases are more
practical that conventional spatial interpolation techniques. These
methods do not aim to replace traditional spatial interpolation methods
and there is no single 'best' approach because the results depend on the
characteristics of each specific dataset. However, this study
demonstrates that the proposed method represents an additional tool that
is a strong candidate for mapping DTB across varied geological and
physiographic settings and potentially could be extended to other types
of spatial data.

# Acknowledgements

We thank Laurence Andriashek (Alberta Geological Survey) for his
significant contribution to the subsurface datasets used in this study
and for providing valuable comments that improved an early version of
this paper. This manuscript was reviewed by Jessica Liggett and Paulina
Branscombe at the Alberta Geological Survey (Alberta Energy Regulator)
and was approved for publication. The data used in this paper is the
result of geological investigations that have occurred over several
decades by the collective efforts of many dedicated geoscientists, data
managers and laboratory staff. For questions about these data, please
contact [AGS-Info\@aer.ca](mailto:AGS-Info@aer.ca){.email}.
